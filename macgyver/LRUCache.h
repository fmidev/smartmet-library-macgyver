// This header was generated by making ChatGPT 4.o and Claude 3.5 iterate on possible improvements

#include <array>
#include <atomic>
#include <cstdint>
#include <list>
#include <memory>
#include <mutex>
#include <optional>
#include <shared_mutex>
#include <stdexcept>
#include <unordered_map>

namespace Fmi
{
template <typename T, std::size_t NumShards = 32>
class LRUCache
{
 private:
  struct Entry
  {
    std::size_t key;
    std::shared_ptr<T> value;

    Entry(std::size_t k, const std::shared_ptr<T>& v) : key(k), value(v) {}
  };

  struct Shard
  {
    std::list<Entry> list;
    std::unordered_map<std::size_t, typename std::list<Entry>::iterator> map;
    mutable std::shared_mutex mutex;
  };

  struct Statistics
  {
    std::atomic<uint64_t> hits{0};
    std::atomic<uint64_t> misses{0};
    std::atomic<uint64_t> inserts{0};
    std::atomic<uint64_t> evictions{0};
  };

  std::array<Shard, NumShards> shards;
  size_t capacity_per_shard;
  Statistics stats;

  size_t getShardIndex(std::size_t key) const
  {
    constexpr std::size_t prime = 2654435761;
    return (key * prime) % NumShards;
  }

 public:
  explicit LRUCache(size_t total_capacity)
      : capacity_per_shard((total_capacity + NumShards - 1) / NumShards)
  {
    static_assert(NumShards > 0, "Number of shards must be greater than 0");
    if (total_capacity == 0)
    {
      throw std::invalid_argument("Total capacity must be greater than 0");
    }
  }

  void put(std::size_t key, const std::shared_ptr<T>& value)
  {
    Shard& shard = shards[getShardIndex(key)];
    std::unique_lock lock(shard.mutex);

    auto it = shard.map.find(key);
    if (it != shard.map.end())
    {
      shard.list.erase(it->second);
      shard.map.erase(it);
    }
    else if (shard.map.size() >= capacity_per_shard)
    {
      auto last = shard.list.back();
      shard.map.erase(last.key);
      shard.list.pop_back();
      stats.evictions.fetch_add(1, std::memory_order_relaxed);
    }

    shard.list.emplace_front(key, value);
    // shard.list.push_front(Entry(key, value));

    shard.map.emplace(key, shard.list.begin());
    stats.inserts.fetch_add(1, std::memory_order_relaxed);
  }

  std::optional<std::shared_ptr<T>> get(std::size_t key)
  {
    Shard& shard = shards[getShardIndex(key)];
    std::shared_lock lock(shard.mutex);

    auto it = shard.map.find(key);
    if (it == shard.map.end())
    {
      stats.misses.fetch_add(1, std::memory_order_relaxed);
      return std::nullopt;
    }

    // Upgrade to a unique lock to modify the LRU list on last accessed elements
    lock.unlock();

    std::unique_lock unique_lock(shard.mutex);
    stats.hits.fetch_add(1, std::memory_order_relaxed);
    shard.list.splice(shard.list.begin(), shard.list, it->second);
    return it->second->value;
  }

  struct CacheStats
  {
    uint64_t hits;
    uint64_t misses;
    uint64_t inserts;
    uint64_t evictions;
  };

  CacheStats getStats() const
  {
    return {stats.hits.load(std::memory_order_relaxed),
            stats.misses.load(std::memory_order_relaxed),
            stats.inserts.load(std::memory_order_relaxed),
            stats.evictions.load(std::memory_order_relaxed)};
  }

  size_t getTotalCapacity() const { return capacity_per_shard * NumShards; }

  size_t getCapacityPerShard() const { return capacity_per_shard; }
};

}  // namespace Fmi
